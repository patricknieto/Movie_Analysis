{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib \n",
    "from bs4 import BeautifulSoup  \n",
    "import logging  \n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dateutil.parser\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    #create a list of page links to the yearly charts. Number of charts set in get_pages()\n",
    "    movie_page = []\n",
    "    \n",
    "    for url in get_pages():\n",
    "        #get soup result from every chart in order to find all of the movie links\n",
    "        soup_result = get_soup(url)\n",
    "        \n",
    "        #loop through every link on chart pages and add them too a larger list of all movie links\n",
    "        for link in generate_links(soup_result):\n",
    "            movie_page.append(link)\n",
    "            \n",
    "            \n",
    "    #Retrieve all necessary info from each page link and save it as a list of dictionaries.\n",
    "    amd = getAllMovieData(movie_page[:3])\n",
    "    \n",
    "    \n",
    "    with open('test.pickle', 'wb') as handle:\n",
    "      pickle.dump(amd, handle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "\n",
    "    except requests.ConnectionError:\n",
    "        print(\"failed to connect\")\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pages ():\n",
    "    \n",
    "    url_list =[]\n",
    "    for year in range(0,10):\n",
    "        for page in range(1,3):\n",
    "            url = 'http://www.boxofficemojo.com/yearly/chart/?page=' + str(page) +'&view=releasedate&view2=domestic&yr=200' + str(year) + '&p=.htm'\n",
    "            url_list.append(url)\n",
    "    for year in range(10,16):\n",
    "        for page in range(1,3):\n",
    "            url = 'http://www.boxofficemojo.com/yearly/chart/?page=' + str(page) +'&view=releasedate&view2=domestic&yr=20' + str(year) + '&p=.htm'\n",
    "            url_list.append(url)\n",
    "\n",
    "    \n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_links(soup):\n",
    "\n",
    "    my_list = []\n",
    "    for link in soup.find(\"body\").find_all('a', href=True):\n",
    "        if link['href'].startswith('/movies/?id='):\n",
    "            my_list.append('http://www.boxofficemojo.com' + link['href'])\n",
    "        elif link['href'] == '' or link['href'].startswith('#'):\n",
    "            continue\n",
    "    link_list = (my_list[1:])\n",
    "    return(link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_actor_listlinks(movie_page):\n",
    "    actorlist = []\n",
    "    for url in movie_page[:10]:\n",
    "        temp_list = []\n",
    "        obj = get_soup(url).find(text=re.compile('Actor'))\n",
    "        for link in obj.findNext('td').find_all('a', href=True):\n",
    "            temp_list.append('http://www.boxofficemojo.com' + link['href'])\n",
    "        actorlist.append(temp_list)\n",
    "    return(actorlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_actor_list(soup):\n",
    "    actornames = []\n",
    "    actorElapsedTimes = []\n",
    "    actordict = defaultdict(list)\n",
    "    obj = soup.find(text=re.compile('Actor'))\n",
    "    if not obj: \n",
    "        return None\n",
    "    else:\n",
    "        for link in obj.findNext('td').find_all('a'):\n",
    "            actornames.append(link.text)\n",
    "            actornames.append(get_actor_date_diff(link['href']))\n",
    "    \n",
    "#     obj = soup.find(text=re.compile('Actor'))\n",
    "#     for link in obj.findNext('td').find_all('a'):\n",
    "#         actorElapsedTimes.append(link['href'])  \n",
    "    actordict = dict(actornames[i:i+2] for i in range(0, len(actornames), 2))\n",
    "    return(actordict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_actor_date_diff(href):\n",
    "    temp_list = []\n",
    "    days_passed = []\n",
    "    href = 'http://www.boxofficemojo.com/'+ href\n",
    "    for link in get_soup(href).find_all('a', href=True):\n",
    "        if link['href'].startswith('/schedule/?view=bydate&release=theatrical&date='):\n",
    "            temp_list.append(to_date(link.text))\n",
    "    days_passed.append(temp_list[1] - temp_list[0])\n",
    "    return(days_passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def to_date(datestring):\n",
    "    date = dateutil.parser.parse(datestring)\n",
    "    return date\n",
    "\n",
    "def money_to_int(moneystring):\n",
    "    moneystring = moneystring.replace(' (Estimate)', '')\n",
    "    moneystring = moneystring.replace('$', '').replace(',', '')\n",
    "    return int(moneystring)\n",
    "\n",
    "def runtime_to_minutes(runtimestring):\n",
    "    runtime = runtimestring.split()\n",
    "    try:\n",
    "        minutes = int(runtime[0])*60 + int(runtime[2])\n",
    "        return minutes\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_movie_value(soup, field_name):\n",
    "    '''Grab a value from boxofficemojo HTML\n",
    "    \n",
    "    Takes a string attribute of a movie on the page and\n",
    "    returns the string in the next sibling object\n",
    "    (the value for that attribute)\n",
    "    or None if nothing is found.\n",
    "    '''\n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    if not obj: \n",
    "        return None\n",
    "    in_box_content = obj.find_parents(class_='mp_box_content')\n",
    "    if in_box_content:\n",
    "        return getBoxContent(obj)\n",
    "    else:\n",
    "        return getHeadTableContent(obj)\n",
    "    \n",
    "\n",
    "def getHeadTableContent(obj):\n",
    "    next_sibling = obj.findNextSibling()\n",
    "    parent_sibling = obj.find_parent().findNextSibling()\n",
    "    if next_sibling:\n",
    "        return next_sibling.text \n",
    "    elif parent_sibling:\n",
    "        return parent_sibling.text\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def getBoxContent(obj):\n",
    "    \n",
    "    other = obj.find_parent('td').find_next_sibling('td')\n",
    "    \n",
    "    if not other:\n",
    "        return None\n",
    "    else:\n",
    "        return other.get_text(strip=True)\n",
    "    \n",
    "def getSingleMovieData(url):\n",
    "    #create a blank dictionary that will be used to track the movie data\n",
    "    movie_data = {}\n",
    "    \n",
    "    #get the raw movie HTML and create a BeautifulSoup object with the text\n",
    "    soup = get_soup(url)\n",
    "    \n",
    "    movie_data['url'] = url\n",
    "    \n",
    "    #get the movie director and add it to `movie_data` dictionary\n",
    "    movie_data['director'] = get_movie_value(soup, 'Director')\n",
    "\n",
    "    #get the movie title\n",
    "    title_string = soup.find('title').text\n",
    "    title = title_string.split('(')[0].strip()\n",
    "    movie_data['title'] = title\n",
    "    \n",
    "    #get the release date\n",
    "    raw_release_date = get_movie_value(soup,'Release Date')\n",
    "    movie_data['release_date'] = to_date(raw_release_date)\n",
    "    \n",
    "    #get the domestic total gross\n",
    "    raw_domestic_total_gross = get_movie_value(soup,'Domestic Total')\n",
    "    movie_data['domestic_total_gross'] = money_to_int(raw_domestic_total_gross)\n",
    "    \n",
    "    #get the MPAA rating\n",
    "    movie_data['rating'] = get_movie_value(soup,'MPAA Rating')\n",
    "    \n",
    "    raw_runtime = get_movie_value(soup,'Runtime')\n",
    "    movie_data['runtime'] = runtime_to_minutes(raw_runtime)\n",
    "    \n",
    "    movie_data['actors'] = get_actor_list(soup)\n",
    "    \n",
    "    actordict = get_actor_list(soup)\n",
    "    movie_data['avg time passed']  =  actordict\n",
    "    \n",
    "    return movie_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAllMovieData(movie_pages):\n",
    "    data = []\n",
    "    count = 0\n",
    "    for i in movie_pages:\n",
    "        movie_data = getSingleMovieData(i)\n",
    "        data.append(movie_data)\n",
    "        count += 1\n",
    "        print(count)\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
